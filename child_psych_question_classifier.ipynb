{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOb6Wqf21+aD0XvQ9Xrl2DF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasse-h/python-NLP/blob/master/child_psych_question_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instructions** 🤔\n",
        "\n",
        "\n",
        "Upon starting, select `Runtime -> run all` from menu above.\n",
        "\n",
        "Once the code has started, you can enter a query to the query cell.\n",
        "\n",
        "Then select the query cell, and `Runtime -> Run after`\n",
        "\n",
        "If the model encounters an error, select `Runtime -> run all` and restart\n",
        "\n",
        "\n",
        "### **Model operating principles**\n",
        "This model first selects whether the question is *closed* or *open-ended*, and after this, it will classify it to the subcategories.\n",
        "\n",
        "Closed questions can be *posing*, *multiple choice* or *too complicated*.\n",
        "\n",
        "Open-ended questiosn can be *directives*, *invitations* or *facilitators*."
      ],
      "metadata": {
        "id": "k9prq20bYejZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up:"
      ],
      "metadata": {
        "id": "zmViE0VDVh2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "u8D1N93o6WhX",
        "outputId": "77f649a4-cf8a-4ce6-d138-c4ec9223e4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.52)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.27.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.1.56)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain_openai) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, constr"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W-CBnBboFHkD"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_core.prompts import *"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-xIUm3J2--mf"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_core.output_parsers import *"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vRqP8diSAHSp"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "-WIenmnE7aEr",
        "outputId": "7993a90f-958f-4171-a7d6-c7c96e3eab87"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.27.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7qQI9hSo7gqX"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "cellView": "form",
        "id": "anvMc-0V78r9"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Enter a query here:**"
      ],
      "metadata": {
        "id": "Wc2Kzx8KVRce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_to_a_child = \"hi!\""
      ],
      "metadata": {
        "id": "PP7rDX1VHSTh"
      },
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main logic:"
      ],
      "metadata": {
        "id": "KD6ZHAD2VW3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "p-g7t9L28ZwN"
      },
      "execution_count": 378,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "llm.model_name = 'gpt-4-turbo'"
      ],
      "metadata": {
        "id": "sqEiokoS-Hi2"
      },
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "closed = \"\"\"questions that presuppose yes or no as an answer, they usually start with modal verbs or phrases such as Can you..., Could you..., Would you... Do you..., Have you..., etc.\"\"\""
      ],
      "metadata": {
        "id": "e3WjpM5yCK38"
      },
      "execution_count": 380,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "option_posing = \"\"\"questions that ask for for confirmation or denial of a presented fact (for example, it was last week, wasn’t it? / was it last week?)\"\"\""
      ],
      "metadata": {
        "id": "XurXmLMPLXp8"
      },
      "execution_count": 381,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multiple_choice = \"\"\"question has a list of options that one is asked to choose from. A list of two or more options that have an “or” in between (such as was it a car, house or boat? Is it tall or short?)\"\"\""
      ],
      "metadata": {
        "id": "k6fKn9FfLY8C"
      },
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "too_complicated = \"\"\"more than one sentence per question, or something else than option posing or multiple choice\"\"\""
      ],
      "metadata": {
        "id": "kYnu3dxoLZH7"
      },
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_ended = \"\"\"questions that do not allow yes or no as an answer, either statements or typically beginning with \"What...\", \"How...\", “Tell me more…”, \"Tell me about...\"\"\""
      ],
      "metadata": {
        "id": "LaOWK5PyCLDL"
      },
      "execution_count": 384,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directive = \"\"\"questions that direct the answerer, where onnly filler words or discourse markers come before the question word (for example: “So, who was there with you?”, “ok, and what is it that he was doing?”).\"\"\""
      ],
      "metadata": {
        "id": "FEy9H1_XLYMf"
      },
      "execution_count": 385,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "invitation = \"\"\"questions that ask the answerer to tell more, such as tell me more about that, tell me more about x, tell me more about it, tell me about x, then what happened? What happened then? what happened after that/before that/first, last/next, and then? \"\"\""
      ],
      "metadata": {
        "id": "tCUmu6KWNYRX"
      },
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facilitator = \"\"\"short utterances that encourage the answerer to continue talking without actually asking anything. These are things like: go on, alright, ok, I see, I understand etc. Also anything that does not fall into other categories)\"\"\""
      ],
      "metadata": {
        "id": "Szgg4ey9Nkrb"
      },
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class QuestionClassificationBasic(BaseModel):\n",
        "    basic_type: constr(regex='^(Closed|Open-Ended)$') = Field(description=\"Is the text open or closed-ended? Choose 'Closed' or 'Open-Ended'.\")\n",
        "    justification: str = Field(description=\"Justify our choice in 10 to 15 words\")"
      ],
      "metadata": {
        "id": "_8Dgo2SmErDI"
      },
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionClassificationOpen(BaseModel):\n",
        "    sub_type: constr(regex='^(Directive|Invitation|Facilitator)$') = Field(description=\"Is the text a directive, invitation or facilitator? Choose between 'Directive', 'Invitation' or 'Facilitator'.\")\n",
        "    justification: str = Field(description=\"Justify our choice in 10 to 15 words\")"
      ],
      "metadata": {
        "id": "kDlGnKePO5I4"
      },
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionClassificationClosed(BaseModel):\n",
        "    sub_type: constr(regex='^(Option Posing|Multiple Choice|Too Complicated)$') = Field(description=\"Is the text option posing, multiple choice or too complicated? Choose between 'Option Posing', 'Multiple Choice' or 'Too Complicated'.\")\n",
        "    justification: str = Field(description=\"Justify our choice in 10 to 15 words\")"
      ],
      "metadata": {
        "id": "bu546He_Mdh9"
      },
      "execution_count": 390,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "basic_output_parser = JsonOutputParser(pydantic_object=QuestionClassificationBasic)"
      ],
      "metadata": {
        "id": "BBznKwhR_8rW"
      },
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "prompt_basic = PromptTemplate(\n",
        "    template=\n",
        "     \"\"\"You are a world-leading forensic psychologist.\n",
        "     Your task is to classify whether an input text is Closed or Open-Ended.\n",
        "     It does not have to be a quesstion, it can be anything, even one word such as 'ok' or 'yes', so you must\n",
        "     be prepared to classify any text accordingly. Never refuse to classify\n",
        "     Thsee two categores are defined as follows:\"\"\"\n",
        "\n",
        "     f\"{closed}\"\n",
        "\n",
        "     f\"{open_ended}\"\n",
        "\n",
        "    \"\"\"Think your decisions carefully, step by step, focusing on features of the text\n",
        "    \\n{format_instructions}\\n{query}\\n\"\"\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": basic_output_parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "dVtDeO9XFe3o"
      },
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_chain = prompt_basic | llm | basic_output_parser"
      ],
      "metadata": {
        "id": "rYJwyuIg_kgL"
      },
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model intermediate classification\n"
      ],
      "metadata": {
        "id": "wlnV8R6EXLjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic_type_classifier = basic_chain.invoke({\"query\": query_to_a_child})\n",
        "print(basic_type_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RecFrS1Q_rws",
        "outputId": "bc1dc442-1373-49e3-a359-a7bd22435914"
      },
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'basic_type': 'Open-Ended', 'justification': \"The text 'hi!' is a greeting not requiring a yes or no.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More logic:"
      ],
      "metadata": {
        "id": "20x3VRApXb5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_classification =  QuestionClassificationOpen if basic_type_classifier['basic_type'] == 'Open-Ended' else QuestionClassificationClosed"
      ],
      "metadata": {
        "id": "MMR_-KYTRBQN"
      },
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_output_parser = JsonOutputParser(pydantic_object=question_classification)"
      ],
      "metadata": {
        "id": "VCaV_3EHRBva"
      },
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "prompt_open = PromptTemplate(\n",
        "    template=\n",
        "     \"\"\"You are a world-leading forensic psychologist.\n",
        "     Your task is to classify whether an input text is\n",
        "     a 'Directive', 'Invitation' or 'Facilitator'.\n",
        "     The input text can be anything, even one word such as 'ok' or 'yes', o you must\n",
        "     be prepared to classify any text.. Never refuse to classify.\n",
        "     Thsee three categores are defined as follows:\"\"\"\n",
        "\n",
        "    f\"{directive}\"\n",
        "\n",
        "    f\"{invitation}\"\n",
        "\n",
        "    f\"{facilitator}\"\n",
        "\n",
        "    \"\"\"Think your decisions carefully, step by step,focusing on features of the text\n",
        "    \\n{format_instructions}\\n{query}\\n\"\"\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": final_output_parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "QXyDxPiqKyQB"
      },
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "prompt_closed = PromptTemplate(\n",
        "    template=\n",
        "     \"\"\"You are a world-leading forensic psychologist.\n",
        "     Your task is to classify whether an input text is\n",
        "     'Option Posing', 'Multiple Choice' or 'Too Complicated'.\n",
        "     The input text can be anything, even one word such as 'ok' or 'yes', so you must\n",
        "     be prepared to classify any text.. Never refuse to classify.\n",
        "     Thsee three categores are defined as follows:\"\"\"\n",
        "\n",
        "    f\"{option_posing}\"\n",
        "\n",
        "    f\"{multiple_choice}\"\n",
        "\n",
        "    f\"{too_complicated}\"\n",
        "\n",
        "    \"\"\"Think your decisions carefully, step by step, focusing on features of the text\n",
        "    \\n{format_instructions}\\n{query}\\n\"\"\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": final_output_parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "LZbR01oiKyYt"
      },
      "execution_count": 398,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "branch = prompt_open if basic_type_classifier['basic_type'] == 'Open-Ended' else prompt_closed"
      ],
      "metadata": {
        "id": "g-yp1z6lKHVy"
      },
      "execution_count": 399,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain = branch | llm | final_output_parser"
      ],
      "metadata": {
        "id": "vkbIa0OCPT3w"
      },
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model final classification"
      ],
      "metadata": {
        "id": "vWV_PkJjXDz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_classifier = final_chain.invoke({\"query\": query_to_a_child})\n",
        "print(final_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z6Cb_OoPjFH",
        "outputId": "314b17af-5f6e-407a-980e-e349a3236f7f"
      },
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sub_type': 'Facilitator', 'justification': \"The text 'hi!' is a short greeting, encouraging interaction.\"}\n"
          ]
        }
      ]
    }
  ]
}