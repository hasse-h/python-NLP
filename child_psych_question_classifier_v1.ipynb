{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/jhZtDmEMRKE32wiN0V1C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasse-h/python-NLP/blob/master/child_psych_question_classifier_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instructions** ü§î\n",
        "\n",
        "\n",
        "Upon starting, select `Runtime -> run all` from menu above.\n",
        "\n",
        "Once the code has started, you can enter a query to the query cell.\n",
        "\n",
        "Then select the query cell, and `Runtime -> Run after`\n",
        "\n",
        "If the model encounters an error, select `Runtime -> run all` and restart\n",
        "\n",
        "\n",
        "### **Model operating principles**\n",
        "This model first selects whether the question is *closed* or *open-ended*, and after this, it will classify it to the subcategories.\n",
        "\n",
        "Closed questions can be *posing questions*, *multiple choice* or *too complicated*.\n",
        "\n",
        "Open-ended questiosn can be *directives*, *invitations* or *facilitators*."
      ],
      "metadata": {
        "id": "k9prq20bYejZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up:"
      ],
      "metadata": {
        "id": "zmViE0VDVh2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "u8D1N93o6WhX",
        "outputId": "4c8df539-71f7-4f22-9abf-5b7432b1c492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_openai\n",
            "  Downloading langchain_openai-0.1.6-py3-none-any.whl (34 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.46 (from langchain_openai)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m302.9/302.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai<2.0.0,>=1.24.0 (from langchain_openai)\n",
            "  Downloading openai-1.28.0-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m320.1/320.1 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tiktoken<1,>=0.5.2 (from langchain_openai)\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (6.0.1)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.0 (from langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
            "  Downloading langsmith-0.1.56-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.24.0->langchain_openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain_openai)\n",
            "  Downloading orjson-3.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.0.7)\n",
            "Installing collected packages: packaging, orjson, jsonpointer, h11, tiktoken, jsonpatch, httpcore, langsmith, httpx, openai, langchain-core, langchain_openai\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 jsonpatch-1.33 jsonpointer-2.4 langchain-core-0.1.52 langchain_openai-0.1.6 langsmith-0.1.56 openai-1.28.0 orjson-3.10.3 packaging-23.2 tiktoken-0.6.0\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, constr"
      ],
      "metadata": {
        "cellView": "form",
        "id": "W-CBnBboFHkD"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_core.prompts import *"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-xIUm3J2--mf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_core.output_parsers import *"
      ],
      "metadata": {
        "cellView": "form",
        "id": "vRqP8diSAHSp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "-WIenmnE7aEr",
        "outputId": "7a87c8e4-34b3-4565-d3e8-9b1d9e2d893e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.28.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ],
      "metadata": {
        "id": "7qQI9hSo7gqX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "anvMc-0V78r9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Enter a query here:**"
      ],
      "metadata": {
        "id": "Wc2Kzx8KVRce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_to_a_child = \"where it happened?\""
      ],
      "metadata": {
        "id": "PP7rDX1VHSTh"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main logic:"
      ],
      "metadata": {
        "id": "KD6ZHAD2VW3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "p-g7t9L28ZwN"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "llm.model_name = 'gpt-4-turbo'"
      ],
      "metadata": {
        "id": "sqEiokoS-Hi2"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "closed = \"\"\"questions that presuppose yes or no as an answer, they usually start with modal verbs or phrases such as Can you..., Could you..., Would you... Do you..., Have you..., etc.\"\"\""
      ],
      "metadata": {
        "id": "e3WjpM5yCK38"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "option_posing = \"\"\"questions that ask for for confirmation or denial of a presented fact (for example, it was last week, wasn‚Äôt it? / was it last week?)\"\"\""
      ],
      "metadata": {
        "id": "XurXmLMPLXp8"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multiple_choice = \"\"\"question has a list of options that one is asked to choose from. A list of two or more options that have an ‚Äúor‚Äù in between (such as was it a car, house or boat? Is it tall or short?)\"\"\""
      ],
      "metadata": {
        "id": "k6fKn9FfLY8C"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "too_complicated = \"\"\"more than one sentence per question, or something else than option posing or multiple choice\"\"\""
      ],
      "metadata": {
        "id": "kYnu3dxoLZH7"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_ended = \"\"\"questions that do not allow yes or no as an answer, either statements or typically beginning with \"What...\", \"How...\", ‚ÄúTell me more‚Ä¶‚Äù, \"Tell me about...\"\"\""
      ],
      "metadata": {
        "id": "LaOWK5PyCLDL"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directive = \"\"\"questions that direct the answerer, where onnly filler words or discourse markers come before the question word (for example: ‚ÄúSo, who was there with you?‚Äù, ‚Äúok, and what is it that he was doing?‚Äù).\"\"\""
      ],
      "metadata": {
        "id": "FEy9H1_XLYMf"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "invitation = \"\"\"questions that ask the answerer to tell more, such as tell me more about that, tell me more about x, tell me more about it, tell me about x, then what happened? What happened then? what happened after that/before that/first, last/next, and then? \"\"\""
      ],
      "metadata": {
        "id": "tCUmu6KWNYRX"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facilitator = \"\"\"short utterances that encourage the answerer to continue talking without actually asking anything. These are things like: go on, alright, ok, I see, I understand etc. Also anything that does not fall into other categories)\"\"\""
      ],
      "metadata": {
        "id": "Szgg4ey9Nkrb"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class QuestionClassificationBasic(BaseModel):\n",
        "    basic_type: constr(regex='^(Closed|Open-Ended)$') = Field(description=\"Is the text open or closed-ended? Choose 'Closed' or 'Open-Ended'.\")\n",
        "    justification: str = Field(description=\"Justify our choice in 10 to 15 words\")"
      ],
      "metadata": {
        "id": "_8Dgo2SmErDI"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionClassificationOpen(BaseModel):\n",
        "    sub_type: constr(regex='^(Directive|Invitation|Facilitator)$') = Field(description=\"Is the text a directive, invitation or facilitator? Choose between 'Directive', 'Invitation' or 'Facilitator'.\")\n",
        "    justification: str = Field(description=\"Justify our choice in 10 to 15 words\")"
      ],
      "metadata": {
        "id": "kDlGnKePO5I4"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionClassificationClosed(BaseModel):\n",
        "    sub_type: constr(regex='^(Option Posing|Multiple Choice|Too Complicated)$') = Field(description=\"Is the text option posing, multiple choice or too complicated? Choose between 'Option Posing', 'Multiple Choice' or 'Too Complicated'.\")\n",
        "    justification: str = Field(description=\"Justify our choice in 10 to 15 words\")"
      ],
      "metadata": {
        "id": "bu546He_Mdh9"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "basic_output_parser = JsonOutputParser(pydantic_object=QuestionClassificationBasic)"
      ],
      "metadata": {
        "id": "BBznKwhR_8rW"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "prompt_basic = PromptTemplate(\n",
        "    template=\n",
        "     \"\"\"You are a world-leading forensic psychologist.\n",
        "     Your task is to classify whether an input text is Closed or Open-Ended.\n",
        "     It does not have to be a quesstion, it can be anything, even one word such as 'ok' or 'yes', so you must\n",
        "     be prepared to classify any text accordingly. Never refuse to classify\n",
        "     Thsee two categores are defined as follows:\"\"\"\n",
        "\n",
        "     f\"{closed}\"\n",
        "\n",
        "     f\"{open_ended}\"\n",
        "\n",
        "    \"\"\"Think your decisions carefully, step by step, focusing on features of the text\n",
        "    \\n{format_instructions}\\n{query}\\n\"\"\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": basic_output_parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "dVtDeO9XFe3o"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_chain = prompt_basic | llm | basic_output_parser"
      ],
      "metadata": {
        "id": "rYJwyuIg_kgL"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model intermediate classification\n"
      ],
      "metadata": {
        "id": "wlnV8R6EXLjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic_type_classifier = basic_chain.invoke({\"query\": query_to_a_child})\n",
        "print(basic_type_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RecFrS1Q_rws",
        "outputId": "130c6b42-c8d5-4cd3-92b6-705df8fe8d4e"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'basic_type': 'Open-Ended', 'justification': \"The phrase 'where it happened?' requests specific information.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More logic:"
      ],
      "metadata": {
        "id": "20x3VRApXb5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_classification =  QuestionClassificationOpen if basic_type_classifier['basic_type'] == 'Open-Ended' else QuestionClassificationClosed"
      ],
      "metadata": {
        "id": "MMR_-KYTRBQN"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_output_parser = JsonOutputParser(pydantic_object=question_classification)"
      ],
      "metadata": {
        "id": "VCaV_3EHRBva"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "prompt_open = PromptTemplate(\n",
        "    template=\n",
        "     \"\"\"You are a world-leading forensic psychologist.\n",
        "     Your task is to classify whether an input text is\n",
        "     a 'Directive', 'Invitation' or 'Facilitator'.\n",
        "     The input text can be anything, even one word such as 'ok' or 'yes', o you must\n",
        "     be prepared to classify any text.. Never refuse to classify.\n",
        "     Thsee three categores are defined as follows:\"\"\"\n",
        "\n",
        "    f\"{directive}\"\n",
        "\n",
        "    f\"{invitation}\"\n",
        "\n",
        "    f\"{facilitator}\"\n",
        "\n",
        "    \"\"\"Think your decisions carefully, step by step,focusing on features of the text\n",
        "    \\n{format_instructions}\\n{query}\\n\"\"\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": final_output_parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "QXyDxPiqKyQB"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "prompt_closed = PromptTemplate(\n",
        "    template=\n",
        "     \"\"\"You are a world-leading forensic psychologist.\n",
        "     Your task is to classify whether an input text is\n",
        "     'Option Posing', 'Multiple Choice' or 'Too Complicated'.\n",
        "     The input text can be anything, even one word such as 'ok' or 'yes', so you must\n",
        "     be prepared to classify any text.. Never refuse to classify.\n",
        "     Thsee three categores are defined as follows:\"\"\"\n",
        "\n",
        "    f\"{option_posing}\"\n",
        "\n",
        "    f\"{multiple_choice}\"\n",
        "\n",
        "    f\"{too_complicated}\"\n",
        "\n",
        "    \"\"\"Think your decisions carefully, step by step, focusing on features of the text\n",
        "    \\n{format_instructions}\\n{query}\\n\"\"\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": final_output_parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "LZbR01oiKyYt"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "branch = prompt_open if basic_type_classifier['basic_type'] == 'Open-Ended' else prompt_closed"
      ],
      "metadata": {
        "id": "g-yp1z6lKHVy"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain = branch | llm | final_output_parser"
      ],
      "metadata": {
        "id": "vkbIa0OCPT3w"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model final classification"
      ],
      "metadata": {
        "id": "vWV_PkJjXDz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_classifier = final_chain.invoke({\"query\": query_to_a_child})\n",
        "print(final_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z6Cb_OoPjFH",
        "outputId": "2a992561-98e4-4152-af23-e33b9e5dadbc"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sub_type': 'Directive', 'justification': 'Begins with a direct question word aiming for specific information.'}\n"
          ]
        }
      ]
    }
  ]
}