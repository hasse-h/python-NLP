{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkELMrDRzDRaZcXXkw0XB+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasse-h/python-NLP/blob/master/child_psych_question_classifier_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Instructions** 🤔\n",
        "\n",
        "\n",
        "Upon starting, select `Runtime -> run all` from menu above.\n",
        "\n",
        "Once the code has started, you can enter a query to the query cell.\n",
        "\n",
        "Then select the query cell, and `Runtime -> Run after`\n",
        "\n",
        "If the model encounters an error, select `Runtime -> run all` and restart\n",
        "\n",
        "\n",
        "### **Model operating principles**\n",
        "GPT-4-turbo first selects whether the question is ***closed*** or ***open-ended***, and after this, it will classify it to the subcategories.\n",
        "\n",
        "Closed questions can be ***posing questions***, ***multiple choice*** or ***too complicated***.\n",
        "\n",
        "Open-ended questiosn can be ***directives***, ***invitations*** or ***facilitators***.\n"
      ],
      "metadata": {
        "id": "k9prq20bYejZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up:"
      ],
      "metadata": {
        "id": "zmViE0VDVh2X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8D1N93o6WhX",
        "outputId": "5fabe062-a699-4959-9819-1ced46092ccc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.6)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.52)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.28.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.1.57)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.46->langchain_openai) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.46->langchain_openai) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.46->langchain_openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.5.2->langchain_openai) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "# @title\n",
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, constr"
      ],
      "metadata": {
        "id": "W-CBnBboFHkD"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_core.prompts import *"
      ],
      "metadata": {
        "id": "-xIUm3J2--mf"
      },
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_core.output_parsers import *"
      ],
      "metadata": {
        "id": "vRqP8diSAHSp"
      },
      "execution_count": 295,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WIenmnE7aEr",
        "outputId": "c6b98955-2869-44c4-9e68-9e0991fa260d"
      },
      "execution_count": 296,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.28.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "from langchain_openai import ChatOpenAI\n",
        "import os"
      ],
      "metadata": {
        "id": "anvMc-0V78r9"
      },
      "execution_count": 297,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Enter your API key here:"
      ],
      "metadata": {
        "id": "s1Dz-xslo27W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = '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'"
      ],
      "metadata": {
        "id": "7qQI9hSo7gqX"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Enter a query here:** ❓"
      ],
      "metadata": {
        "id": "Wc2Kzx8KVRce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_to_a_child = \"could you tell about it\""
      ],
      "metadata": {
        "id": "PP7rDX1VHSTh"
      },
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Category definitions"
      ],
      "metadata": {
        "id": "JCD2XJYFpqMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "closed = \"\"\"start with modal verbs or phrases such as Can you...,\n",
        "Could you..., Would you... Do you..., Have you..., etc.\"\"\""
      ],
      "metadata": {
        "id": "e3WjpM5yCK38"
      },
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "option_posing = \"\"\"questions that that ask the user to choose whether they could\n",
        "or would do something to confirma or deny of a presented fact (for example,\n",
        "it was last week, wasn’t it? / was it last week?)\"\"\""
      ],
      "metadata": {
        "id": "XurXmLMPLXp8"
      },
      "execution_count": 451,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multiple_choice = \"\"\"question has a list of options that one is asked\n",
        "to choose from. A list of two or more options that have an “or” in between\n",
        "(such as was it a car, house or boat? Is it tall or short?)\"\"\""
      ],
      "metadata": {
        "id": "k6fKn9FfLY8C"
      },
      "execution_count": 452,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "other = \"\"\"more than one sentence per question, or something\n",
        "else than option posing or multiple choice\"\"\""
      ],
      "metadata": {
        "id": "kYnu3dxoLZH7"
      },
      "execution_count": 453,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open = \"\"\"either a statement or typically beginning with\n",
        "\"What...\", \"How...\", “Tell me more…”, \"Tell me about...\"\"\""
      ],
      "metadata": {
        "id": "LaOWK5PyCLDL"
      },
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directive = \"\"\"questions that direct the answerer, where onnly\n",
        "filler words or discourse markers come before the question word\n",
        "(for example: “So, who was there with you?”, “ok, and what is it that he was doing?”).\"\"\""
      ],
      "metadata": {
        "id": "FEy9H1_XLYMf"
      },
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "invitation = \"\"\"questions that ask the answerer to tell more, such as\n",
        " tell me more about that, tell me more about x, tell me more about it, tell me about x,\n",
        " then what happened? What happened then?\n",
        "what happened after that/before that/first, last/next, and then? \"\"\""
      ],
      "metadata": {
        "id": "tCUmu6KWNYRX"
      },
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "facilitator = \"\"\"short utterances that encourage the answerer to\n",
        "continue talking without actually asking anything.\n",
        "These are things like: go on, alright, ok, I see, I understand etc.\n",
        "Also anything that does not fall into other categories)\"\"\""
      ],
      "metadata": {
        "id": "Szgg4ey9Nkrb"
      },
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main logic:"
      ],
      "metadata": {
        "id": "KD6ZHAD2VW3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "llm = ChatOpenAI()"
      ],
      "metadata": {
        "id": "p-g7t9L28ZwN"
      },
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "llm.model_name = 'gpt-4-turbo'"
      ],
      "metadata": {
        "id": "sqEiokoS-Hi2"
      },
      "execution_count": 459,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "class QuestionClassificationBasic(BaseModel):\n",
        "    basic_type: constr(regex='^(Closed|Open)$') = Field(description=\"Choose '1' or '2' according to the definition.\")\n",
        "    justification: str = Field(description=\"Justify your choice in 10 to 15 words\")"
      ],
      "metadata": {
        "id": "_8Dgo2SmErDI"
      },
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionClassificationOpen(BaseModel):\n",
        "    sub_type: constr(regex='^(Directive|Invitation|Facilitator)$') = Field(description=\"Is the text a directive, invitation or facilitator? Choose between 'Directive', 'Invitation' or 'Facilitator'.\")\n",
        "    justification: str = Field(description=\"Justify our choice in 10 to 15 words\")"
      ],
      "metadata": {
        "id": "kDlGnKePO5I4"
      },
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuestionClassificationClosed(BaseModel):\n",
        "    sub_type: constr(regex='^(Option Posing|Multiple Choice|Too Complicated)$') = Field(description=\"Is the text option posing, multiple choice or too complicated? Choose between 'Option Posing', 'Multiple Choice' or 'Too Complicated'.\")\n",
        "    justification: str = Field(description=\"Justify our choice in 10 to 15 words\")"
      ],
      "metadata": {
        "id": "bu546He_Mdh9"
      },
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "basic_output_parser = JsonOutputParser(pydantic_object=QuestionClassificationBasic)"
      ],
      "metadata": {
        "id": "BBznKwhR_8rW"
      },
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "prompt_basic = PromptTemplate(\n",
        "    template=\n",
        "     \"\"\"You are a world-leading forensic psychologist.\n",
        "     Your task is to classify whether an input text is of type 1 or type 2 according to our definitions below.\n",
        "     Do not trust on your intuition, follow the definition instead.\n",
        "     It does not have to be a quesstion, it can be anything, even one word such as 'ok' or 'yes', so you must\n",
        "     be prepared to classify any text accordingly. Never refuse to classify\n",
        "     Thsee two categores are defined as follows:\"\"\"\n",
        "\n",
        "      \"Closed\"\n",
        "     f\"{closed}\"\n",
        "\n",
        "      \"Open\"\n",
        "     f\"{open}\"\n",
        "\n",
        "    \"\"\"Think your decisions carefully, step by step, focusing on features of the text\n",
        "    \\n{format_instructions}\\n{query}\\n\"\"\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": basic_output_parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "dVtDeO9XFe3o"
      },
      "execution_count": 464,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "basic_chain = prompt_basic | llm | basic_output_parser"
      ],
      "metadata": {
        "id": "rYJwyuIg_kgL"
      },
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model basic classification\n",
        "\n",
        "This takes only the first three words of the question into account, as this is sufficient for determining if the question is Open or Closed"
      ],
      "metadata": {
        "id": "wlnV8R6EXLjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic_type_classifier = basic_chain.invoke({\"query\": ' '.join(query_to_a_child.split()[:3])})\n",
        "print(basic_type_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RecFrS1Q_rws",
        "outputId": "7870b14d-4a91-48cb-fd66-a69353b4b7c3"
      },
      "execution_count": 466,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'basic_type': 'Closed', 'justification': \"Starts with 'Could you', matching Closed category.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## More logic:"
      ],
      "metadata": {
        "id": "20x3VRApXb5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question_classification =  QuestionClassificationOpen if basic_type_classifier['basic_type'] == 'Open' else QuestionClassificationClosed"
      ],
      "metadata": {
        "id": "MMR_-KYTRBQN"
      },
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_output_parser = JsonOutputParser(pydantic_object=question_classification)"
      ],
      "metadata": {
        "id": "VCaV_3EHRBva"
      },
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "prompt_open = PromptTemplate(\n",
        "    template=\n",
        "     \"\"\"You are a world-leading forensic psychologist.\n",
        "     Your task is to classify whether an input text is\n",
        "     a 'Directive', 'Invitation' or 'Facilitator'.\n",
        "     The input text can be anything, even one word such as 'ok' or 'yes', o you must\n",
        "     be prepared to classify any text.. Never refuse to classify.\n",
        "     Thsee three categores are defined as follows:\"\"\"\n",
        "\n",
        "    f\"{directive}\"\n",
        "\n",
        "    f\"{invitation}\"\n",
        "\n",
        "    f\"{facilitator}\"\n",
        "\n",
        "    \"\"\"Think your decisions carefully, step by step,focusing on features of the text\n",
        "    \\n{format_instructions}\\n{query}\\n\"\"\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": final_output_parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "QXyDxPiqKyQB"
      },
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "prompt_closed = PromptTemplate(\n",
        "    template=\n",
        "     \"\"\"You are a world-leading forensic psychologist.\n",
        "     Your task is to classify whether an input text is\n",
        "     'Option Posing', 'Multiple Choice' or 'Other'.\n",
        "     The input text can be anything, even one word such as 'ok' or 'yes', so you must\n",
        "     be prepared to classify any text.. Never refuse to classify.\n",
        "     Thsee three categores are defined as follows:\"\"\"\n",
        "\n",
        "    f\"{option_posing}\"\n",
        "\n",
        "    f\"{multiple_choice}\"\n",
        "\n",
        "    f\"{other}\"\n",
        "\n",
        "    \"\"\"Think your decisions carefully, step by step, focusing on features of the text\n",
        "    \\n{format_instructions}\\n{query}\\n\"\"\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": final_output_parser.get_format_instructions()},\n",
        ")"
      ],
      "metadata": {
        "id": "LZbR01oiKyYt"
      },
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "branch = prompt_open if basic_type_classifier['basic_type'] == 'Open' else prompt_closed"
      ],
      "metadata": {
        "id": "g-yp1z6lKHVy"
      },
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_chain = branch | llm | final_output_parser"
      ],
      "metadata": {
        "id": "vkbIa0OCPT3w"
      },
      "execution_count": 472,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model final classification\n",
        "\n",
        "This takes the entire questions into account"
      ],
      "metadata": {
        "id": "vWV_PkJjXDz5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_classifier = final_chain.invoke({\"query\": query_to_a_child})\n",
        "print(final_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9z6Cb_OoPjFH",
        "outputId": "696c9588-e4ff-44fe-d5b6-1f43c79371bc"
      },
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'sub_type': 'Option Posing', 'justification': 'The text poses a question confirming a time.'}\n"
          ]
        }
      ]
    }
  ]
}